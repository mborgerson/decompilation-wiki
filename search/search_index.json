{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"The Decompilation Wiki","text":"<p>The Decompilation Wiki is a collection of categorized information on all things decompilation. From real-world applications to cutting-edge research papers, the Decompilation Wiki has it all! Join our Discord below for active community engagement. To get involved, see our contribution guide.</p> <p></p>"},{"location":"#what-is-decompilation","title":"What Is Decompilation?","text":"<p>Interestingly, the term \"decompilation\" and its definition are still argued about by researchers. However, most people agree that decompilation is the reversal of compilation.  By that definition, decompilation is the process of turning low-level machine code into a higher-level representation.</p> <p>In many cases, this means turning machine code, like x86 assembly, into source code, like C. This methodology can also be applied to languages like Java, which create custom byte codes. The difficulty and accuracy of decompilation can vary per language target<sup>1</sup>.</p> <p>Decompilation has wide applications across cyber security, including:</p> <ul> <li>reverse engineering (the understanding of programs)</li> <li>vulnerability discovery (the understanding of program flaws)</li> <li>malware classification</li> <li>program repair</li> <li>and much more...</li> </ul>"},{"location":"#wiki-goals","title":"Wiki Goals?","text":"<p>This wiki has two main goals:</p> <ol> <li>Making decompilation knowledge more accessible to new-comers in the field</li> <li>Categorizing research and tooling to make future decompilation progress easier</li> </ol> <p>To accomplish the first goal, it is highly encouraged to link public code when adding a technique.  Additionally, we will store tutorials for self-rolling (to a degree) your own decompiler components. </p> <p>To accomplish the second goal, we will attempt to rapidly categorize new research and tools in the area. These categorizations may not be agreed upon at first, however, we will update them as the community hits consensus.  In this way, we can quickly attempt to taxonomize the area of decompilation while iterating on it. </p>"},{"location":"#who-made-this","title":"Who Made This?","text":"<p>The Decompilation Wiki was started by Zion Leonahenahe Basque, but is sustained by the contributions of the decompilation community. Both closed and open-source developers are welcome! </p> <p>The wiki is highly inspired by the following sources:</p> <ul> <li>Program-Transformation.org: a wiki on program transformations, including some decompilation.</li> <li>CTF Wiki: a wiki for Capture the Flag, inspiring this layout and design.</li> <li>\"30 Years into Scientific Binary Decompilation\", Dr. Ruoyu (Fish) Wang: a source of information on decompilers.</li> </ul> <ol> <li> <p>Yakdan, Khaled, et al. \"Helping johnny to analyze malware: A usability-optimized decompiler and malware analysis user study.\" 2016 IEEE Symposium on Security and Privacy (SP). IEEE, 2016.\u00a0\u21a9</p> </li> </ol>"},{"location":"contributing/","title":"Contributing Guide","text":"<p>Thank you for wanting to contribute to the Decompilation Wiki!  Below are some simple tips to make requests for changes easier to review for the community. </p> <p>If there are ever questions on good contributions, opening issues and discussion on Discord are the best mediums for feedback.</p>"},{"location":"contributing/#general-contributing-guide","title":"General Contributing Guide","text":"<p>To make a change, open a PR on the GitHub repo after forking and making a branch. There are two types of changes you might make while contributing to the wiki:</p> <ol> <li>Adding a listing to a new decompiler/tool/blog/...</li> <li>Updating a section regarding fundamental or applied research</li> </ol> <p>The best way to make PRs for these types of changes are different and found below.</p>"},{"location":"contributing/#tool-listing-change","title":"Tool Listing Change","text":"<p>When making changes to this area try to include three things: 1. A link to any high-level description of it (papers are ok). 2. Tags relevant to the tool (see sections like Community Blogs) 3. Tool source link if open-source </p> <p>PRs in this category require no justification and will very likely be merged after a simple review of the content. </p>"},{"location":"contributing/#research-area-update","title":"Research Area Update","text":"<p>Changes to research areas require a little more than tool changes. If the change is a simple typo, no justification is needed and the PR will be accepted.</p> <p>However, if the change is more content-based, then it will require more explanations.  When making changes here, it will be important to either include a citation or a well-thought-out argument against current wording/posturing. Any links to community discussions are always appreciated, such as Reddit threads, Twitter threads, or blogs. </p> <p>Additionally, any PRs that require larger discussion will likely be tied to a Discussion post on GitHub. </p> <p>Thank you for your efforts to improve the Decompilation Wiki!</p>"},{"location":"applications/overview/","title":"Decompiler Applications","text":"<p>Across the internet, there are many ways people have used decompilers in the wild. In this section, you can find a collection of some of those use cases.</p> <p>As an example, some decompilation uses include: </p> <ul> <li>Program Reversing: used to understand how a program works and how to interact with it.</li> <li>Program Reconstruction: used to completely (or partially) recompile the targetted binary</li> <li>Automated Program Repair: used for patching faulty programs</li> <li>Manual &amp; Automated Vuln Discovery: used for finding vulnerabilities</li> </ul> <p>For links to full decompilers, see the Decompilers section. </p>"},{"location":"applications/program_reconstruction/","title":"Program Reconstruction","text":"<p>When source code is unavailable for a compiled program, users may want to recover the source code so they can make edits to it and recompile it.  In the video game scene, this can be useful for modding or full program recovery.  </p>"},{"location":"applications/program_reconstruction/#video-games","title":"Video Games","text":"<p>A list of video games that are being reversed with a decompiler to recompile either the entire game or individual functions. Most projects include a percent completion of the estimated program recompilation:</p> <ul> <li>Halo: Combat Evolved (halo-re)</li> <li>Lego Island (1997)</li> <li>Paper Mario</li> </ul>"},{"location":"applied_research/code_sim/","title":"Code Similarity","text":""},{"location":"applied_research/code_sim/#introduction","title":"Introduction","text":"<p>In cases such as malware identification, the ability to estimate code similarity among binaries is critical<sup>1</sup>. Research in this area generally looks at ways to improve the reliability of similarity detection among binaries. </p> <p>There is little work in the direct use of decompilation for code similarity, however, the general work in the binary analysis is frequent.  These works are included here since they often touch on or improve fundamental components in decompilation. </p> <p>The most direct research in this area has utilized Ghidra decompilation to identify inlined functions in decompilation<sup>2</sup>. </p>"},{"location":"applied_research/code_sim/#related-works","title":"Related Works","text":"<p>Many works have progressed towards binary-based code similarity that do not explicitly use decompilation <sup>1</sup><sup>3</sup><sup>4</sup><sup>5</sup><sup>6</sup>. Most of these works have improved code similarity techniques indirectly by improving it for their specific uses cases.  These uses have included malware identification<sup>1</sup>, duplicated bug hunting<sup>3</sup><sup>4</sup>, and code reuse<sup>5</sup>.</p> <p>Recent work has suggested that machine learning has made significant strides in this area<sup>6</sup>.</p> <ol> <li> <p>Hu, Xin, Tzi-cker Chiueh, and Kang G. Shin. \"Large-scale malware indexing using function-call graphs.\" Proceedings of the 16<sup>th</sup> ACM conference on Computer and communications security. 2009.\u00a0\u21a9\u21a9\u21a9</p> </li> <li> <p>Ahmed, Toufique, Premkumar Devanbu, and Anand Ashok Sawant. \"Finding Inlined Functions in Optimized Binaries.\" arXiv preprint arXiv:2103.05221 (2021).\u00a0\u21a9</p> </li> <li> <p>Feng, Qian, et al. \"Scalable graph-based bug search for firmware images.\" Proceedings of the 2016 ACM SIGSAC conference on computer and communications security. 2016.\u00a0\u21a9\u21a9</p> </li> <li> <p>Eschweiler, Sebastian, Khaled Yakdan, and Elmar Gerhards-Padilla. \"Discovre: Efficient cross-architecture identification of bugs in binary code.\" Ndss. Vol. 52. 2016.\u00a0\u21a9\u21a9</p> </li> <li> <p>Mirzaei, Omid, et al. \"Scrutinizer: Detecting code reuse in malware via decompilation and machine learning.\" Detection of Intrusions and Malware, and Vulnerability Assessment: 18<sup>th</sup> International Conference, DIMVA 2021, Virtual Event, July 14\u201316, 2021, Proceedings 18. Springer International Publishing, 2021.\u00a0\u21a9\u21a9</p> </li> <li> <p>Marcelli, Andrea, et al. \"How machine learning is solving the binary function similarity problem.\" 31<sup>st</sup> USENIX Security Symposium (USENIX Security 22). 2022.\u00a0\u21a9\u21a9</p> </li> </ol>"},{"location":"applied_research/overview/","title":"Applied Research Overview","text":"<p>Decompiler research that does not neatly fit into one of the fundamental areas is defined here as applied research. Research in this area contributes to a specific use-case of decompilation that may not necessarily improve base decompilation.</p> <p>As an example, most researchers would agree that variable name prediction in stripped binaries is an important research area<sup>1</sup>.  However, as it stands, variable name prediction does not improve any fundamental research area (except neural decompilation). As such, we consider it an applied research area, with that target being human-comprehensible decompilation. </p> <p>This section is ever-growing as new research areas are explored in decompilation.  Currently, the following areas exist:</p> <ul> <li>Symbol Recovery: recovering the names or high-level symbols that are associated with a function or variable</li> <li>Code Similarity: measuring how similar (for various uses) some binary is to another</li> <li>Vulnerability Discovery: tuning decompilation to be better used for vulnerability discovery</li> </ul>"},{"location":"applied_research/overview/#other-research","title":"Other Research","text":"<p>Some research areas don't have enough work to define a label for them. The following works are listed here:</p> <ul> <li>Byte-exact recompilable decompilation<sup>4</sup></li> <li>Patchable decompilation<sup>2</sup></li> <li>Verifiable decompilation<sup>3</sup></li> <li>Higher abstraction support<sup>5</sup><sup>6</sup><sup>7</sup></li> </ul> <ol> <li> <p>Pal, Kuntal Kumar, et al. \"\"Len or index or count, anything but v1\": Predicting Variable Names in Decompilation Output with Transfer Learning.\" 2024 IEEE Symposium on Security and Privacy (SP). IEEE Computer Society, 2024.\u00a0\u21a9</p> </li> <li> <p>Reiter, Pemma, et al. \"Automatically mitigating vulnerabilities in x86 binary programs via partially recompilable decompilation.\" arXiv preprint arXiv:2202.12336 (2022).\u00a0\u21a9</p> </li> <li> <p>Verbeek, Freek, Pierre Olivier, and Binoy Ravindran. \"Sound C Code Decompilation for a subset of x86-64 Binaries.\" Software Engineering and Formal Methods: 18<sup>th</sup> International Conference, SEFM 2020, Amsterdam, The Netherlands, September 14\u201318, 2020, Proceedings 18. Springer International Publishing, 2020.\u00a0\u21a9</p> </li> <li> <p>Schulte, Eric, et al. \"Evolving exact decompilation.\" Workshop on Binary Analysis Research (BAR). 2018.\u00a0\u21a9</p> </li> <li> <p>Fokin, Alexander, et al. \"SmartDec: approaching C++ decompilation.\" 2011 18<sup>th</sup> Working Conference on Reverse Engineering. IEEE, 2011.\u00a0\u21a9</p> </li> <li> <p>Wu, Ruoyu, et al. \"{DnD}: A {Cross-Architecture} deep neural network decompiler.\" 31<sup>st</sup> USENIX Security Symposium (USENIX Security 22). 2022.\u00a0\u21a9</p> </li> <li> <p>Liu, Zhibo, et al. \"Decompiling x86 deep neural network executables.\" 32<sup>nd</sup> USENIX Security Symposium (USENIX Security 23). 2023.\u00a0\u21a9</p> </li> </ol>"},{"location":"applied_research/symbol_recovery/","title":"Symbol Recovery","text":""},{"location":"applied_research/symbol_recovery/#introduction","title":"Introduction","text":"<p>A symbol, in the context of binaries, is a name associated with an object. In most cases, this is either function names or variable names.  It is often useful for reverse engineering to have the original symbols to more quickly understand the purpose of an object. </p>"},{"location":"applied_research/symbol_recovery/#symbol-recovery-example","title":"Symbol Recovery Example","text":"<p>Below is a snippet of a C program: <pre><code>int mode;\nchar* name;\nlong long timezone;\n</code></pre></p> <p>After compiling and stripping, a common developer practice, the binary will be decompiled to something like: <pre><code>int v1;\nchar* v2;\nlong long v3;\n</code></pre></p> <p>Assuming the types are recovered perfectly (hard), it is still hard to understand what these variables do. </p>"},{"location":"applied_research/symbol_recovery/#previous-work","title":"Previous Work","text":"<p>Research in this area has been concerned with the recovery of both variable names<sup>1</sup><sup>2</sup><sup>4</sup><sup>5</sup><sup>6</sup><sup>7</sup> and function names<sup>3</sup><sup>5</sup>.  Approaches have varied between using neural networks<sup>2</sup><sup>3</sup><sup>6</sup><sup>7</sup>, machine translation<sup>4</sup>, probabilistic methods<sup>5</sup>, and BERT-based language models<sup>1</sup>. In many cases, the bottleneck of this work has been dataset generation<sup>1</sup>.</p> <ol> <li> <p>Pal, Kuntal Kumar, et al. \"\"Len or index or count, anything but v1\": Predicting Variable Names in Decompilation Output with Transfer Learning.\" 2024 IEEE Symposium on Security and Privacy (SP). IEEE Computer Society, 2024.\u00a0\u21a9\u21a9\u21a9</p> </li> <li> <p>Dramko, Luke, et al. \"DIRE and its data: Neural decompiled variable renamings with respect to software class.\" ACM Transactions on Software Engineering and Methodology 32.2 (2023): 1-34.\u00a0\u21a9\u21a9</p> </li> <li> <p>Artuso, Fiorella, et al. \"Function naming in stripped binaries using neural networks.\" arXiv preprint arXiv:1912.07946 (2019).\u00a0\u21a9\u21a9</p> </li> <li> <p>Jaffe, Alan, et al. \"Meaningful variable names for decompiled code: A machine translation approach.\" Proceedings of the 26<sup>th</sup> Conference on Program Comprehension. 2018.\u00a0\u21a9\u21a9</p> </li> <li> <p>He, Jingxuan, et al. \"Debin: Predicting debug information in stripped binaries.\" Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security. 2018.\u00a0\u21a9\u21a9\u21a9</p> </li> <li> <p>DIRE: A Neural Approach to Decompiled Identifier Naming\u00a0\u21a9\u21a9</p> </li> <li> <p>Chen, Qibin, et al. \"Augmenting decompiler output with learned variable names and types.\" 31<sup>st</sup> USENIX Security Symposium (USENIX Security 22). 2022.\u00a0\u21a9\u21a9</p> </li> </ol>"},{"location":"applied_research/vuln_discovery/","title":"Vulnerability Discovery","text":"<p>In many uses of decompilation, humans, or machines, aim to understand if a program is safe. To verify if this program is safe, they attempt to do the opposite: find vulnerabilities in the program. Some decompilers, and their associated research, have attempted to tune their decompilers to be better at this task<sup>1</sup>. There has also been work at evaluating decompilers by how well they perform with source tools<sup>2</sup>. </p> <p>Most research in this area has focused on static analysis<sup>1</sup><sup>2</sup><sup>3</sup> and symbolic execution<sup>4</sup> applied to decompilation. Since these tasks have often been researched with source, an application to binaries has been achieved through decompilation. </p> <ol> <li> <p>Botacin, Marcus, et al. \"Revenge is a dish served cold: Debug-oriented malware decompilation and reassembly.\" Proceedings of the 3<sup>rd</sup> Reversing and Offensive-oriented Trends Symposium. 2019.\u00a0\u21a9\u21a9</p> </li> <li> <p>Mantovani, Alessandro, et al. \"The Convergence of Source Code and Binary Vulnerability Discovery--A Case Study.\" Proceedings of the 2022 ACM on Asia Conference on Computer and Communications Security. 2022.\u00a0\u21a9\u21a9</p> </li> <li> <p>Park, Jihee, et al. \"Static Analysis of JNI Programs via Binary Decompilation.\" IEEE Transactions on Software Engineering (2023).\u00a0\u21a9</p> </li> <li> <p>Han, HyungSeok, et al. \"QueryX: Symbolic Query on Decompiled Code for Finding Bugs in COTS Binaries.\" 2023 IEEE Symposium on Security and Privacy (SP). IEEE, 2023.\u00a0\u21a9</p> </li> </ol>"},{"location":"decompilers/directory/","title":"Decompiler Directory","text":"<p>Over the years, many decompilers have been made by both hackers and academics alike.  In this directory, you will find a listing of all known (at least to the wiki authors) decompilers. </p> <p>Each decompiler should also be listed with some minimal facts about their differences. </p>"},{"location":"decompilers/directory/#legend","title":"Legend","text":"<ul> <li>\ud83c\udf10: open-source</li> <li>\ud83d\udc80: inactive (2 years without activity)</li> <li>0\ufe0f\u20e3: binary decompiler (compiled languages)</li> <li>\ud83d\udd0c: implemented as a plugin to another decompiler</li> </ul>"},{"location":"decompilers/directory/#alphabetical-order","title":"Alphabetical Order","text":"Decompiler Attributes Intermediate Language Release Date angr decompiler 0\ufe0f\u20e3, \ud83c\udf10 VEX, AIL 2018 Binary Ninja 0\ufe0f\u20e3 BNIL 2015 dewolf 0\ufe0f\u20e3, \ud83c\udf10, \ud83d\udd0c BNIL 2015 DREAM 0\ufe0f\u20e3, \ud83c\udf10, \ud83d\udc80, \ud83d\udd0c Micro Code 2015 Ghidra 0\ufe0f\u20e3, \ud83c\udf10 P-Code ? Hoppper 0\ufe0f\u20e3 ? ? IDA Pro (HexRays) 0\ufe0f\u20e3 Micro Code 2007 JEB 0\ufe0f\u20e3 ? 2014 Reko 0\ufe0f\u20e3, \ud83c\udf10 ? 2007 Relyze 0\ufe0f\u20e3, \ud83d\udc80 ? ? RetDec 0\ufe0f\u20e3, \ud83c\udf10 ? ? r2dec 0\ufe0f\u20e3, \ud83c\udf10 ? ? Snowman 0\ufe0f\u20e3, \ud83c\udf10, \ud83d\udc80 ? 2015 fcd 0\ufe0f\u20e3, \ud83c\udf10, \ud83d\udc80 ? 2015"},{"location":"decompilers/history/","title":"History","text":""},{"location":"decompilers/tools/","title":"Tools","text":"<p>The community continues to extend decompilers outside of fundamental improvements in the form of plugins and tools. Here you can find a listing of tools and plugins used by the community. </p>"},{"location":"decompilers/tools/#generic-tools","title":"Generic Tools","text":"<p>Tools that work in most popular decompilers.</p> <ul> <li>BinDiff: A decompiler-based diffing tool for binaries.</li> <li>BinSync: A Git-based collaboration framework for decompilers. Supports IDA, Ghidra, Binja, and angr decompiler.</li> <li>DogBolt: A web-based tool for comparing popular decompiler's decompilation.</li> <li>RevSync: A synchronization tool for decompilers. Supports IDA &amp; Binja. </li> </ul>"},{"location":"decompilers/decompiler/angr/","title":"angr decompiler","text":""},{"location":"decompilers/decompiler/binary_ninja/","title":"Binary Ninja","text":""},{"location":"decompilers/decompiler/ghidra/","title":"Ghidra","text":""},{"location":"decompilers/decompiler/ida_pro/","title":"IDA Pro (HexRays)","text":""},{"location":"fundamentals/evaluation/","title":"Quality Evaluation","text":""},{"location":"fundamentals/evaluation/#introduction","title":"Introduction","text":"<p>The best way to measure the quality of overall decompilation is still an open problem in decompilation research. However, there have been a variety of methods for evaluating the quality of individual fundamental components in decompilation.</p>"},{"location":"fundamentals/evaluation/#control-flow-structuring-metrics","title":"Control Flow Structuring Metrics","text":"<p>Early evaluations in control flow structuring utilized metrics from software engineering.  As such, these metrics were not compared to their original source, but instead used standalone.  This was useful because these metrics could be computed in real-world scenarios of decompilation use and reduced in runtime.  The following early metrics were used:</p> <ul> <li>Gotos<sup>1</sup><sup>2</sup><sup>3</sup><sup>4</sup><sup>5</sup></li> <li>Full-function Recompilability<sup>2</sup></li> <li>Lines of Code (LoC)<sup>4</sup></li> <li>McCabe Cyclomatic Complexity (MCC)<sup>5</sup></li> </ul> <p>In all but the case of function recompilability, the decompiler would want to optimize for reducing all of these metrics. However, recent work has argued against the pure reduction of these metrics<sup>5</sup>.  The SAILR paper<sup>5</sup>, argues that these metrics should be measured relative to its source (like machine translation). The following metrics were used as compared to source:</p> <ul> <li>Gotos</li> <li>Boolean Expression</li> <li>Function Calls</li> <li>Graph Edit Distance (GED)</li> </ul> <p>In each metric, the score closest to the source is the best structured decompilation.  Since these metrics can only be used with knowledge of source, they can only be used when developing a decompiler (not optimized in runtime).</p>"},{"location":"fundamentals/evaluation/#variable-typing-metrics","title":"Variable Typing Metrics","text":"<p>Unlike control flow structuring metrics, most evaluations for variable typing have focused on comparing choices to the source<sup>6</sup><sup>7</sup><sup>8</sup><sup>9</sup>. Generally, these evaluations would flow like the following:</p> <ol> <li>Extract the ground-truth types from the source (usually with DWARF info)</li> <li>Guess variables and types from decompilation</li> <li>See how often (or how close) each chosen variable location and type was to source</li> </ol> <p>Some evaluations have also measured how conservative they were at approximating types<sup>7</sup>.</p>"},{"location":"fundamentals/evaluation/#human-evaluation","title":"Human Evaluation","text":"<p>Some work has utilized human evaluations to understand the quality of decompilation<sup>10</sup><sup>11</sup>.  These works have focused on qualitative metrics, such as users' perception of the code's complexity<sup>10</sup>.  Additionally, the Decomperson<sup>12</sup> paper studied how humans might make decompilation themselves when given assembly.</p> <p>Since how humans rate decompilation is related to how they reverse engineer, some work has explored how humans reverse and exploit binaries. These studies have mainly focused on how hackers use tooling and techniques for reverse engineering<sup>15</sup><sup>16</sup>. </p>"},{"location":"fundamentals/evaluation/#other-general-metrics","title":"Other General Metrics","text":"<p>Some work has constructed a taxonomy of decompiler-to-source errors<sup>13</sup>. That work categorized and identified many errors that occur when decompiling a binary. </p> <p>Other work has identified general methods by which we may test the correctness of decompilation<sup>14</sup>. Relatedly, some structuring work has attempted to measure this through recompiliability<sup>2</sup>. </p>"},{"location":"fundamentals/evaluation/#dataset-generation","title":"Dataset Generation","text":"<p>The question of \"what dataset?\" to use has also been an issue in decompilation. Additionally, compiled binaries can sometimes be hard to access. Some related work has explored ways to generate bigger binary datasets for the evaluation of binary tools like decompilers<sup>17</sup>.</p> <ol> <li> <p>Cifuentes, Cristina. Reverse compilation techniques. Queensland University of Technology, Brisbane, 1994.\u00a0\u21a9</p> </li> <li> <p>Brumley, David, et al. \"Native x86 decompilation using Semantics-Preserving structural analysis and iterative Control-Flow structuring.\" 22<sup>nd</sup> USENIX Security Symposium (USENIX Security 13). 2013.\u00a0\u21a9\u21a9\u21a9</p> </li> <li> <p>Basque, Zion Leonahenahe, et al. \"Ahoy sailr! there is no need to dream of c: A compiler-aware structuring algorithm for binary decompilation.\" 33st USENIX Security Symposium (USENIX Security 24). 2024.\u00a0\u21a9</p> </li> <li> <p>Yakdan, Khaled, et al. \"No More Gotos: Decompilation Using Pattern-Independent Control-Flow Structuring and Semantic-Preserving Transformations.\" NDSS. 2015.\u00a0\u21a9\u21a9</p> </li> <li> <p>Gussoni, Andrea, et al. \"A comb for decompiled c code.\" Proceedings of the 15<sup>th</sup> ACM Asia Conference on Computer and Communications Security. 2020.\u00a0\u21a9\u21a9\u21a9\u21a9</p> </li> <li> <p>Noonan, Matt, Alexey Loginov, and David Cok. \"Polymorphic type inference for machine code.\" Proceedings of the 37<sup>th</sup> ACM SIGPLAN Conference on Programming Language Design and Implementation. 2016.\u00a0\u21a9</p> </li> <li> <p>Lee, JongHyup, Thanassis Avgerinos, and David Brumley. \"TIE: Principled reverse engineering of types in binary programs.\" (2011)\u00a0\u21a9\u21a9</p> </li> <li> <p>Zhang, Zhuo, et al. \"Osprey: Recovery of variable and data structure via probabilistic analysis for stripped binary.\" 2021 IEEE Symposium on Security and Privacy (SP). IEEE, 2021.\u00a0\u21a9</p> </li> <li> <p>Chen, Qibin, et al. \"Augmenting decompiler output with learned variable names and types.\" 31<sup>st</sup> USENIX Security Symposium (USENIX Security 22). 2022.\u00a0\u21a9</p> </li> <li> <p>Yakdan, Khaled, et al. \"Helping johnny to analyze malware: A usability-optimized decompiler and malware analysis user study.\" 2016 IEEE Symposium on Security and Privacy (SP). IEEE, 2016.\u00a0\u21a9\u21a9</p> </li> <li> <p>Enders, Steffen, et al. \"dewolf: Improving Decompilation by leveraging User Surveys.\" arXiv preprint arXiv:2205.06719 (2022).\u00a0\u21a9</p> </li> <li> <p>Decomperson: How Humans Decompile and What We Can Learn From It\u00a0\u21a9</p> </li> <li> <p>Dramko, Luke, et al. \"A Taxonomy of C Decompiler Fidelity Issues.\" 33st USENIX Security Symposium (USENIX Security 24). 2024.\u00a0\u21a9</p> </li> <li> <p>How far we have come: Testing decompilation correctness of C decompilers\u00a0\u21a9</p> </li> <li> <p>Nosco, Timothy, et al. \"The industrial age of hacking.\" 29<sup>th</sup> USENIX Security Symposium (USENIX Security 20). 2020.\u00a0\u21a9</p> </li> <li> <p>Mantovani, Alessandro, et al. \"{RE-Mind}: a First Look Inside the Mind of a Reverse Engineer.\" 31<sup>st</sup> USENIX Security Symposium (USENIX Security 22). 2022.\u00a0\u21a9</p> </li> <li> <p>Singhal, Vidush, et al. \"Cornucopia: A Framework for Feedback Guided Generation of Binaries.\" Proceedings of the 37<sup>th</sup> IEEE/ACM International Conference on Automated Software Engineering. 2022.\u00a0\u21a9</p> </li> </ol>"},{"location":"fundamentals/neural_decompilation/","title":"Neural Decompilation","text":""},{"location":"fundamentals/neural_decompilation/#introduction","title":"Introduction","text":"<p>This wiki defines a neural decompiler as the following:</p> <ul> <li>Any decompiler that wholly replaces one or many fundamental decompiler components with a machine-learning model.</li> </ul> <p>As such, decompilation produced by a neural decompiler is neural decompilation. Approaches in this area are promising because they often offer a more generic solution to decompilation.  Instead of a decompiler developer having to program a component, the component is learned from binaries and their corresponding source<sup>1</sup>. </p>"},{"location":"fundamentals/neural_decompilation/#previous-works","title":"Previous Works","text":"<p>The earliest academic work in this area is the 2018 work \"Using Recurrent Neural Networks for Decompilation\"<sup>1</sup>.  The work utilized a Recurrent Neural Network (RNN) to replace all components downstream from CFG recovery, omitting the lifting phase to train on x86 assembly.  Subsequent work also focused on x86, while changing their method for decompilation to Neural Machine Translation<sup>2</sup><sup>3</sup><sup>4</sup><sup>5</sup><sup>7</sup> and a more refined RNN<sup>6</sup>. The most reliable of these works, Coda, claims an average of \"82% program recovery accuracy on unseen binary sample(s)\"<sup>6</sup>. The notable Beyond-The-C, also introduces early work to turn binary code into multiple languages other than C <sup>7</sup>.</p> <p>With the recent popularization of Large Language Models (LLM), like ChatGPT, early work has utilized LLMs for end-to-end decompilation<sup>8</sup>.  Other related work in the area has used LLMs to improve the structured output of other decompilers<sup>9</sup>. </p> <ol> <li> <p>Katz, Deborah S., Jason Ruchti, and Eric Schulte. \"Using recurrent neural networks for decompilation.\" 2018 IEEE 25<sup>th</sup> International Conference on Software Analysis, Evolution and Reengineering (SANER). IEEE, 2018.\u00a0\u21a9\u21a9</p> </li> <li> <p>Katz, Omer, et al. \"Towards neural decompilation.\" arXiv preprint arXiv:1905.08325 (2019).\u00a0\u21a9</p> </li> <li> <p>Liang, Ruigang, et al. \"Neutron: an attention-based neural decompiler.\" Cybersecurity 4 (2021): 1-13.\u00a0\u21a9</p> </li> <li> <p>Liang, Ruigang, et al. \"Semantics-recovering decompilation through neural machine translation.\" arXiv preprint arXiv:2112.15491 (2021).\u00a0\u21a9</p> </li> <li> <p>Cao, Ying, et al. \"Boosting neural networks to decompile optimized binaries.\" Proceedings of the 38<sup>th</sup> Annual Computer Security Applications Conference. 2022.\u00a0\u21a9</p> </li> <li> <p>Fu, Cheng, et al. \"Coda: An end-to-end neural program decompiler.\" Advances in Neural Information Processing Systems 32 (2019).\u00a0\u21a9\u21a9</p> </li> <li> <p>Hosseini, Iman, and Brendan Dolan-Gavitt. \"Beyond the C: Retargetable decompilation using neural machine translation.\" arXiv preprint arXiv:2212.08950 (2022).\u00a0\u21a9\u21a9</p> </li> <li> <p>Tan, Hanzhuo, et al. \"LLM4Decompile: Decompiling Binary Code with Large Language Models.\" arXiv preprint arXiv:2403.05286 (2024).\u00a0\u21a9</p> </li> <li> <p>Hu, Peiwei, Ruigang Liang, and Kai Chen. \"DeGPT: Optimizing Decompiler Output with LLM.\"\u00a0\u21a9</p> </li> </ol>"},{"location":"fundamentals/overview/","title":"Overview","text":""},{"location":"fundamentals/overview/#introduction","title":"Introduction","text":"<p>Modern decompilation is built on many techniques from both binary analysis and classic compilation algorithms.  Fundamental research in this area focuses on improving base decompilation across all languages.</p> <p>Some academic work has defined fundamental decompilation research to include three areas<sup>1</sup>, this wiki includes an extra fourth one:</p> <ol> <li>Control Flow Graph Recovery: the extraction of (lifted) directed graphs indicating code execution</li> <li>Type Recovery: the typing and discovery of variables in the program</li> <li>Control Flow Structuring: the conversion of a CFG to a linear code-like output</li> <li>Quality Evaluation: the measurement of overall decompilation quality</li> </ol> <p>Each of these fundamental areas affects the quality of one another in some way. For instance, improvements to type recovery can directly improve the results of control flow structuring<sup>4</sup>. With this in mind, we included the fourth area, quality evaluation in decompilation, as fundamental. We include this area because it influences the methodologies for the previous three areas and few works have standardized on metrics<sup>1</sup><sup>2</sup><sup>3</sup>.</p> <p>Other works, such as function name recovery can be found in the Applied Research section.</p>"},{"location":"fundamentals/overview/#generic-decompilation-pipeline","title":"Generic Decompilation Pipeline","text":"<p>Modern decompilers are comprised of fundamental components that can be directly mapped to each fundamental research area. Most decompilers follow a pipeline flow that resembles the following<sup>3</sup>:</p> <p></p> <p>The evaluation component is optional but has been used in the past for on-the-fly decision-making in other components like control flow structuring<sup>5</sup>. Each component can be implemented at various levels, such as the optional lifting phase in control flow recovery. </p> <p>In the case of neural decompilation, most components are replaced by the machine learning model. </p> <ol> <li> <p>Basque, Zion Leonahenahe, et al. \"Ahoy SAILR! There is no need to DREAM of C: A compiler-aware structuring algorithm for binary decompilation.\" 33st USENIX Security Symposium (USENIX Security 24). 2024.\u00a0\u21a9\u21a9</p> </li> <li> <p>Yakdan, Khaled, et al. \"Helping johnny to analyze malware: A usability-optimized decompiler and malware analysis user study.\" 2016 IEEE Symposium on Security and Privacy (SP). IEEE, 2016.\u00a0\u21a9</p> </li> <li> <p>Brumley, David, et al. \"Native x86 decompilation using Semantics-Preserving structural analysis and iterative Control-Flow structuring.\" 22<sup>nd</sup> USENIX Security Symposium (USENIX Security 13). 2013.\u00a0\u21a9\u21a9</p> </li> <li> <p>Lee, JongHyup, Thanassis Avgerinos, and David Brumley. \"TIE: Principled reverse engineering of types in binary programs.\" (2011).\u00a0\u21a9</p> </li> <li> <p>Gussoni, Andrea, et al. \"A comb for decompiled c code.\" Proceedings of the 15<sup>th</sup> ACM Asia Conference on Computer and Communications Security. 2020.\u00a0\u21a9</p> </li> </ol>"},{"location":"fundamentals/type_recovery/","title":"Type Recovery","text":""},{"location":"fundamentals/type_recovery/#introduction","title":"Introduction","text":"<p>Type recovery is the process of identifying high-level variables and their types from a binary<sup>1</sup>, usually in the form of a CFG. This wiki groups variable identification with type recovery since they are often intertwined in decompilation<sup>2</sup>. </p> <p>In most decompilers, the typing system requires a well-formed CFG, usually lifted, on which to perform analysis.  Analysis phases can be thought to work in two refining stages:</p> <ol> <li>Variable Identification: discover initial locations and their boundaries</li> <li>Type Constraining: utilizing the variables' uses in the code, make constraints for size and choose a type.</li> </ol> <p>This process is often iterative between constraint building and variable identification.  Variable identification also includes retyping/resizing as more constraints are gathered. </p> <p></p>"},{"location":"fundamentals/type_recovery/#typing-example","title":"Typing Example","text":"<p>A simple C program is shown below: <pre><code>int main(int argc, char** argv) {\n    char* str = argv[1];\n    puts(str);\n}\n</code></pre></p> <p>After compiling and disassembling: <pre><code>gcc example.c -o example &amp;&amp; objdump -D -M intel example | grep \"&lt;main&gt;:\" -A 12\n</code></pre></p> <p>We are left with the following: <pre><code>0000000000001149 &lt;main&gt;:\n    1149:   f3 0f 1e fa             endbr64\n    114d:   55                      push   rbp\n    114e:   48 89 e5                mov    rbp,rsp\n    1151:   48 83 ec 20             sub    rsp,0x20\n    1155:   89 7d ec                mov    DWORD PTR [rbp-0x14],edi\n    1158:   48 89 75 e0             mov    QWORD PTR [rbp-0x20],rsi\n    115c:   48 8b 45 e0             mov    rax,QWORD PTR [rbp-0x20]\n    1160:   48 8b 40 08             mov    rax,QWORD PTR [rax+0x8]\n    1164:   48 89 45 f8             mov    QWORD PTR [rbp-0x8],rax\n    1168:   48 8b 45 f8             mov    rax,QWORD PTR [rbp-0x8]\n    116c:   48 89 c7                mov    rdi,rax\n    116f:   e8 dc fe ff ff          call   1050 &lt;puts@plt&gt;\n</code></pre></p> <p>A naive variable recovery algorithm might do the following: <pre><code>int main(int a1, long long a2) {\n    int v1; // rbp-0x14\n    long long v2; // rbp-0x20\n    long long v3; // rax\n    long long v4; // rbp-0x8\n    v1 = a1;\n    v2 = a2;\n    v3 = *(&amp;v2 + 1);\n    v4 = v3\n    puts((char *) v4);\n}\n</code></pre></p> <p>However, since <code>puts</code> is known to take a <code>char *</code> as the first argument this would allow <code>v4</code> to be constrained to be a <code>char *</code>. Back-propagating this type constraint to the earlier variables, we get the following: <pre><code>int main(int a1, char** a2) {\n    int v1; // rbp-0x14\n    char** v2; // rbp-0x20\n    char * v3; // rax\n    char * v4; // rbp-0x8\n    v1 = a1;\n    v2 = a2;\n    v3 = v2[1];\n    v4 = v3\n    puts(v4);\n}\n</code></pre></p>"},{"location":"fundamentals/type_recovery/#variable-identification","title":"Variable Identification","text":"<p>Variable identification seeks to map memory locations and registers to high-level variables in the targeted language output (usually C). Early decompilers often mapped variables to locations based on their simple accesses <sup>2</sup>. Later work has followed up on this by expanding the set of uses supported for a variable location identification <sup>1</sup>.  Identified variables often have many candidates for size (because of their potential type). These candidates have often been reduced to a single type based on their type sinks<sup>3</sup>, uses that have explicit types like in a call argument. </p>"},{"location":"fundamentals/type_recovery/#type-constraining","title":"Type Constraining","text":"<p>Type constraining is directly linked to variable identification since the use of the variable is affected by its size (arrays vs primitive types). Previous works in this area have looked at multiple ways to gather and reduce types for variables. Some of these include: def-use analysis<sup>1</sup><sup>5</sup><sup>6</sup>, library awareness<sup>3</sup><sup>5</sup><sup>6</sup>, emulation<sup>4</sup>, lattice-solving<sup>7</sup><sup>8</sup>, and machine learning<sup>9</sup><sup>10</sup>.</p> <p>Of these works, typing involving lattice-based methods<sup>7</sup><sup>8</sup>, also known as push-down typing, is the most popular among modern open-source decompilers. </p> <ol> <li> <p>Balakrishnan, Gogul, and Thomas Reps. \"Divine: Discovering variables in executables.\" International Workshop on Verification, Model Checking, and Abstract Interpretation. Berlin, Heidelberg: Springer Berlin Heidelberg, 2007.\u00a0\u21a9\u21a9\u21a9</p> </li> <li> <p>Mycroft, Alan. \"Type-based decompilation (or program reconstruction via type reconstruction).\" European Symposium on Programming. Berlin, Heidelberg: Springer Berlin Heidelberg, 1999.\u00a0\u21a9\u21a9</p> </li> <li> <p>Lin, Zhiqiang, Xiangyu Zhang, and Dongyan Xu. \"Automatic reverse engineering of data structures from binary execution.\" Proceedings of the 11<sup>th</sup> Annual Information Security Symposium. 2010.\u00a0\u21a9\u21a9</p> </li> <li> <p>Slowinska, Asia, Traian Stancescu, and Herbert Bos. \"Howard: A Dynamic Excavator for Reverse Engineering Data Structures.\" NDSS. 2011.\u00a0\u21a9</p> </li> <li> <p>Haller, Istvan, Asia Slowinska, and Herbert Bos. \"Mempick: High-level data structure detection in c/c++ binaries.\" 2013 20<sup>th</sup> Working Conference on Reverse Engineering (WCRE). IEEE, 2013.\u00a0\u21a9\u21a9</p> </li> <li> <p>Jin, Wesley, et al. \"Recovering C++ objects from binaries using inter-procedural data-flow analysis.\" Proceedings of ACM SIGPLAN on Program Protection and Reverse Engineering Workshop 2014. 2014.\u00a0\u21a9\u21a9</p> </li> <li> <p>Noonan, Matt, Alexey Loginov, and David Cok. \"Polymorphic type inference for machine code.\" Proceedings of the 37<sup>th</sup> ACM SIGPLAN Conference on Programming Language Design and Implementation. 2016.\u00a0\u21a9\u21a9</p> </li> <li> <p>Lee, JongHyup, Thanassis Avgerinos, and David Brumley. \"TIE: Principled reverse engineering of types in binary programs.\" (2011)\u00a0\u21a9\u21a9</p> </li> <li> <p>Zhang, Zhuo, et al. \"Osprey: Recovery of variable and data structure via probabilistic analysis for stripped binary.\" 2021 IEEE Symposium on Security and Privacy (SP). IEEE, 2021.\u00a0\u21a9</p> </li> <li> <p>Chen, Qibin, et al. \"Augmenting decompiler output with learned variable names and types.\" 31<sup>st</sup> USENIX Security Symposium (USENIX Security 22). 2022.\u00a0\u21a9</p> </li> </ol>"},{"location":"fundamentals/cf_structuring/gotoless/","title":"Gotoless Structuring","text":""},{"location":"fundamentals/cf_structuring/gotoless/#introduction","title":"Introduction","text":"<p>Gotoless structuring is a type of structuring that ignores some compiler patterns to make code that contains no gotos<sup>1</sup>. According to this work, these gotos are signs of unstructured code which is bad for readability<sup>1</sup><sup>2</sup>. </p> <p>The most famous of these works, and the founder of the area, is the DREAM decompiler<sup>1</sup>. The DREAM decompiler used reaching conditions on statements to condense and reduce decompilation. </p> <p>The followup to this work, which is a hybrid of gotoless and schema-based methods, is the rev.ng<sup>2</sup> decompiler.  They used a method called \"Combing\", which duplicated nodes in the original graph to get rid of unstructured regions. </p> <ol> <li> <p>Yakdan, Khaled, et al. \"No More Gotos: Decompilation Using Pattern-Independent Control-Flow Structuring and Semantic-Preserving Transformations.\" NDSS. 2015.\u00a0\u21a9\u21a9\u21a9</p> </li> <li> <p>Gussoni, Andrea, et al. \"A comb for decompiled c code.\" Proceedings of the 15<sup>th</sup> ACM Asia Conference on Computer and Communications Security. 2020.\u00a0\u21a9\u21a9</p> </li> </ol>"},{"location":"fundamentals/cf_structuring/overview/","title":"Structuring Overview","text":""},{"location":"fundamentals/cf_structuring/overview/#introduction","title":"Introduction","text":"<p>Academically introduced in Dr. Cifuentes' 1994 Dissertation<sup>1</sup>, decompilation control flow structuring is the process used to turn a control flow graph (CFG) into a structured high-level language.  Control flow structuring in decompilation is highly related to the general control flow structuring process found in compiler research. Although the goal of control flow structuring, referred to as structuring, is to output linear high-level code, the level of abstraction of that code is open research. Additionally, few works exist in structuring for targeting language output other than C. </p>"},{"location":"fundamentals/cf_structuring/overview/#general-structuring-example","title":"General Structuring Example","text":"<p>Although often thought of in the context of assembly, control flow structuring requires a control flow graph and conditions <sup>3</sup>.  For example, the attributed control flow graph below can be used as input:</p> <pre><code>                            +-----+\n                            |  A  |\n                            +-----+\n                              |   |\n                           ~x |   +--+\n                              V      |\n                         +-----+     |\n                         |  B  |     | x\n                         +-----+     |\n                           |  +--+   |\n                        ~y |     | y |\n                           V     V   V\n                       +-----+  +-----+\n                       |  D  |  |  C  |\n                       +-----+  +-----+\n                            |    |\n                            V    V\n                            +-----+\n                            |  E  |\n                            +-----+\n</code></pre> <p>Using a schmea-based structuring algorithm, the graph can be turned into the following C:</p> <pre><code>A();\nif(x)\n    goto label_c;\nB();\nif (y) {\nlabel_c:\n    C();\n}\nelse {\n    D();\n}\nE();\n</code></pre> <p>There are multiple ways of turning the graph into linear C code <sup>4</sup>. For instance, the first condition on <code>x</code> can be flipped, changing where the <code>goto</code> appears and how many <code>if</code> scopes exist in the program. </p>"},{"location":"fundamentals/cf_structuring/overview/#types-of-structuring","title":"Types of Structuring","text":"<p>There are two dominant types of structuring algorithms<sup>8</sup>:</p> <ol> <li>Schema-based: Algorithms that construct code based on pre-known graph patterns that are omitted by compilers. These algorithms attempt to only make structured code when they are aware of a direct mapping to its source structure. </li> <li>Gotoless: Algorithms that prioritize removing all unstructured regions from code. These algorithms may use schema-based methods initially but are unique in their pattern-matching of structures that may not exist in its source. </li> </ol> <p>The biggest difference between these two is their reliance on known compiler patterns<sup>5</sup>.  In schema-based algorithms, the decompiler author creates a set of known compiler output patterns to recover a target language.  In gotoless algorithms, the decompiler author uses patterns outside of graph schemas, which may be compiler and language-independent. One such example is condition-based structuring, as used in the DREAM <sup>5</sup> decompiler. </p>"},{"location":"fundamentals/cf_structuring/overview/#related-fields","title":"Related Fields","text":"<p>Structuring in decompilation was directly inspired by compiler works in structuring and general data-flow analysis<sup>3</sup>.  One of these earliest works was the 1970s paper \"Control flow analysis.\"<sup>2</sup>, which laid out the fundamental ideas for constructing control flow graphs. Additionally, many of the ideas for eliminating gotos, which were often a byproduct of schema-based structuring, were inspired by work in restructuring source code<sup>6</sup> <sup>7</sup>.</p> <ol> <li> <p>Cifuentes, Cristina. Reverse compilation techniques. Queensland University of Technology, Brisbane, 1994.\u00a0\u21a9</p> </li> <li> <p>Allen, Frances E. \"Control flow analysis.\" ACM Sigplan Notices 5.7 (1970): 1-19.\u00a0\u21a9</p> </li> <li> <p>Brumley, David, et al. \"Native x86 decompilation using Semantics-Preserving structural analysis and iterative Control-Flow structuring.\" 22<sup>nd</sup> USENIX Security Symposium (USENIX Security 13). 2013.\u00a0\u21a9\u21a9</p> </li> <li> <p>Basque, Zion Leonahenahe. \u201c30 Years of Decompilation and the Unsolved Structuring Problem: Part 1.\u201d Mahaloz.Re, 2 Jan. 2024, https://mahaloz.re/dec-history-pt1. Accessed 11 Apr. 2024.\u00a0\u21a9</p> </li> <li> <p>Yakdan, Khaled, et al. \"No More Gotos: Decompilation Using Pattern-Independent Control-Flow Structuring and Semantic-Preserving Transformations.\" NDSS. 2015.\u00a0\u21a9\u21a9</p> </li> <li> <p>Williams, M. Howard, and G. Chen. \"Restructuring pascal programs containing goto statements.\" The Computer Journal 28.2 (1985): 134-137.\u00a0\u21a9</p> </li> <li> <p>Erosa, Ana M., and Laurie J. Hendren. \"Taming control flow: A structured approach to eliminating goto statements.\" Proceedings of 1994 IEEE International Conference on Computer Languages (ICCL'94). IEEE, 1994.\u00a0\u21a9</p> </li> <li> <p>Basque, Zion Leonahenahe, et al. \"Ahoy sailr! there is no need to dream of c: A compiler-aware structuring algorithm for binary decompilation.\" 33st USENIX Security Symposium (USENIX Security 24). 2024.\u00a0\u21a9</p> </li> </ol>"},{"location":"fundamentals/cf_structuring/schema-based/","title":"Schema-based Structuring","text":""},{"location":"fundamentals/cf_structuring/schema-based/#introduction","title":"Introduction","text":"<p>Schema-based structuring is a type of structuring that depends on a set of known compiler graph patterns<sup>1</sup>. With this in mind, a decompiler must know all of the compiler graph patterns to generate code that is structured<sup>3</sup> (contains no gotos). An example of this type of structuring can be found in the overview section.  Schema-based structuring techniques are the most popular techniques among decompilers<sup>1</sup><sup>2</sup><sup>4</sup><sup>5</sup><sup>6</sup>.</p>"},{"location":"fundamentals/cf_structuring/schema-based/#example-graph-patterns","title":"Example Graph Patterns","text":"<p>Example graph patterns, from Cifuentes 1994 dissertation<sup>1</sup>, can be seen below:</p> <p></p>"},{"location":"fundamentals/cf_structuring/schema-based/#approaches","title":"Approaches","text":"<p>After the foundational dissertation from Cifuentes, the Phoenix<sup>2</sup> work improved on structuring by adding more condition patterns.  These patterns allowed for more correct structures (like loop reductions). </p> <p>Follow-ups to this work all used gotoless<sup>3</sup><sup>4</sup> structuring methods until the SAILR<sup>5</sup> work in 2024. The SAILR work improved on the gotoless algorithms by introducing a new type of schema that \"reverts compiler optimizations.\"</p> <ol> <li> <p>Cifuentes, Cristina. Reverse compilation techniques. Queensland University of Technology, Brisbane, 1994.\u00a0\u21a9\u21a9\u21a9</p> </li> <li> <p>Brumley, David, et al. \"Native x86 decompilation using Semantics-Preserving structural analysis and iterative Control-Flow structuring.\" 22<sup>nd</sup> USENIX Security Symposium (USENIX Security 13). 2013.\u00a0\u21a9\u21a9</p> </li> <li> <p>Yakdan, Khaled, et al. \"No More Gotos: Decompilation Using Pattern-Independent Control-Flow Structuring and Semantic-Preserving Transformations.\" NDSS. 2015.\u00a0\u21a9\u21a9</p> </li> <li> <p>Gussoni, Andrea, et al. \"A comb for decompiled c code.\" Proceedings of the 15<sup>th</sup> ACM Asia Conference on Computer and Communications Security. 2020.\u00a0\u21a9\u21a9</p> </li> <li> <p>Basque, Zion Leonahenahe, et al. \"Ahoy sailr! there is no need to dream of c: A compiler-aware structuring algorithm for binary decompilation.\" 33st USENIX Security Symposium (USENIX Security 24). 2024.\u00a0\u21a9\u21a9</p> </li> <li> <p>\u010eurfina, Luk\u00e1\u0161, et al. \"Design of a retargetable decompiler for a static platform-independent malware analysis.\" Information Security and Assurance: International Conference, ISA 2011, Brno, Czech Republic, August 15-17, 2011. Proceedings. Springer Berlin Heidelberg, 2011.\u00a0\u21a9</p> </li> </ol>"},{"location":"fundamentals/cfg_recovery/disassembly/","title":"Disassembling","text":""},{"location":"fundamentals/cfg_recovery/disassembly/#introduction","title":"Introduction","text":"<p>Work in this area dates back to the 90s and can generally be broken up into two disassemblying techniques<sup>1</sup>:</p> <ol> <li>Linear Sweep<sup>2</sup>: starts disassembling from the first byte in the program and linearly continues</li> <li>Recursive Traversal<sup>3</sup>: disassembles by following control flow as it is discovered</li> </ol> <p>Linear sweep is considered to be more prone to errors in programs that embed data in the middle of their code[1].  Additionally, all disassembling techniques confront the main problem of Instruction boundary identification (IBI)<sup>4</sup>, which dictates when an instruction starts and ends.</p>"},{"location":"fundamentals/cfg_recovery/disassembly/#previous-works","title":"Previous Works","text":"<p>Relevant work for decompilation focused on improving both the accuracy and scalability of disassembling programs<sup>2</sup><sup>6</sup>.  Some of these works have improved these methods for work on deobfuscated binaries<sup>3</sup> as well as benign ones. Recent work in the area has focused on reassemblable disassembly<sup>4</sup><sup>5</sup>. This area is promising for decompilation as it makes re-compilable decompilation more achievable <sup>5</sup>. </p> <p>There has also been work to measure the accuracy of these disassembling frameworks by comparing their results to that of an instrumented compiler<sup>7</sup><sup>8</sup>. </p> <ol> <li> <p>Kruegel, Christopher, et al. \"Static disassembly of obfuscated binaries.\" USENIX security Symposium. Vol. 13. 2004.\u00a0\u21a9</p> </li> <li> <p>Free Software Foundation. GNU Binary Utilities, Mar 2002. https://www.gnu.org/software/binutils/manual/.\u00a0\u21a9\u21a9</p> </li> <li> <p>C. Cifuentes and K. Gough. Decompilation of Binary Programs. Software Practice &amp; Experience, 25(7):811-829, July 1995.\u00a0\u21a9\u21a9</p> </li> <li> <p>Flores-Montoya, Antonio, and Eric Schulte. \"Datalog disassembly.\" 29<sup>th</sup> USENIX Security Symposium (USENIX Security 20). 2020.\u00a0\u21a9\u21a9</p> </li> <li> <p>Ruoyu Wang, Yan Shoshitaishvili, Antonio Bianchi, Aravind Machiry, John Grosen, Paul Grosen, Christopher Kruegel, and Giovanni Vigna. Ramblr: Making reassembly great again. In NDSS, 2017\u00a0\u21a9\u21a9</p> </li> <li> <p>Andriesse, Dennis, et al. \"An {In-Depth} Analysis of Disassembly on {Full-Scale} x86/x64 Binaries.\" 25<sup>th</sup> USENIX security symposium (USENIX security 16). 2016.\u00a0\u21a9</p> </li> <li> <p>Pang, Chengbin, et al. \"Ground truth for binary disassembly is not easy.\" 31<sup>st</sup> USENIX Security Symposium (USENIX Security 22). 2022.\u00a0\u21a9</p> </li> <li> <p>Pang, Chengbin, et al. \"Sok: All you ever wanted to know about x86/x64 binary disassembly but were afraid to ask.\" 2021 IEEE symposium on security and privacy (SP). IEEE, 2021.\u00a0\u21a9</p> </li> </ol>"},{"location":"fundamentals/cfg_recovery/func_recov/","title":"Function Identification","text":"<p>Function identification is used to identify the instruction boundaries of a function in the binary. For decompilation purposes, this serves as crucial information for the flow of code in the program.</p> <p>There have been generally three approaches:</p> <ol> <li>Pattern based (with weights)<sup>1</sup><sup>2</sup></li> <li>Machine-learning based<sup>3</sup></li> </ol> <ol> <li> <p>Bao, Tiffany, et al. \"{BYTEWEIGHT}: Learning to recognize functions in binary code.\" 23<sup>rd</sup> USENIX Security Symposium (USENIX Security 14). 2014.\u00a0\u21a9</p> </li> <li> <p>Andriesse, Dennis, Asia Slowinska, and Herbert Bos. \"Compiler-agnostic function detection in binaries.\" 2017 IEEE European symposium on security and privacy (EuroS&amp;P). IEEE, 2017.\u00a0\u21a9</p> </li> <li> <p>Shin, Eui Chul Richard, Dawn Song, and Reza Moazzezi. \"Recognizing functions in binaries with neural networks.\" 24<sup>th</sup> USENIX security symposium (USENIX Security 15). 2015.\u00a0\u21a9</p> </li> </ol>"},{"location":"fundamentals/cfg_recovery/jump_res/","title":"Jump Resolving","text":"<p>After recovering a CFG from a binary, there may be calls that have an unknown target.  Indirect jump resolving is the process of discovering some, or all, of the targets those jumps may go to.  A basic implementation of this is Switch statements resolving, since they are often compiled into indirect jumps <sup>1</sup>.</p> <p>The work in this area has mostly focused on ways to reduce the total set of analyzed pointers while doing pointer analysis<sup>2</sup><sup>3</sup>. Additionally, these works have used program knowledge to further reduce constant-reducible pointers, like those found in class initialization in C++<sup>2</sup>. </p>"},{"location":"fundamentals/cfg_recovery/jump_res/#indirect-jump-example","title":"Indirect Jump Example","text":"<p>A simple indirect jump looks like the following in x86: <pre><code>jmp [rax];\n</code></pre></p> <p>Since pointer analysis is considered hard, it may not be trivial to find the value of <code>rax</code>.</p> <ol> <li> <p>Brumley, David, et al. \"Native x86 decompilation using {Semantics-Preserving} structural analysis and iterative {Control-Flow} structuring.\" 22<sup>nd</sup> USENIX Security Symposium (USENIX Security 13). 2013.\u00a0\u21a9</p> </li> <li> <p>Kim, Sun Hyoung, et al. \"Refining Indirect Call Targets at the Binary Level.\" NDSS. 2021.\u00a0\u21a9\u21a9</p> </li> <li> <p>Kim, Sun Hyoung, et al. \"Binpointer: towards precise, sound, and scalable binary-level pointer analysis.\" Proceedings of the 31<sup>st</sup> ACM SIGPLAN International Conference on Compiler Construction. 2022.\u00a0\u21a9</p> </li> </ol>"},{"location":"fundamentals/cfg_recovery/lifting/","title":"Program Lifting","text":""},{"location":"fundamentals/cfg_recovery/lifting/#introduction","title":"Introduction","text":"<p>In program lifting, disassembly is converted into an intermediate language (IL)<sup>1</sup>, which is also referred to as an intermediate representation (IR). Converting disassembly to an IL allows decompiler developers to make optimizations on the IL level which apply to multiple architectures. </p> <p>There exist many ILs for analysis of programs, but some of the most notable ones for decompilation are tied to binary analysis. Most binary analysis platforms that have created or used an IL often follow the same techniques but mostly differ in their later use of ILs<sup>1</sup><sup>2</sup><sup>3</sup><sup>4</sup>.  One such use is recompilable decompilation, which can be made easier by lifting to compiled ILs like LLVM-IR<sup>5</sup><sup>6</sup>. Another use-case has been the verification of decompilation correctness<sup>8</sup>.</p> <p>Similar to static analysis, most ILs used in decompilation support some form of static single assignment (SSA) since it simplifies some analyses<sup>7</sup>.</p>"},{"location":"fundamentals/cfg_recovery/lifting/#example-lifted-program","title":"Example Lifted Program","text":"<p>Below is some example x86 assembly of a simple C program: <pre><code>0000000000001129 &lt;main&gt;:\n    1129:   f3 0f 1e fa             endbr64\n    112d:   55                      push   rbp\n    112e:   48 89 e5                mov    rbp,rsp\n    1131:   89 7d ec                mov    DWORD PTR [rbp-0x14],edi\n    1134:   83 7d ec 02             cmp    DWORD PTR [rbp-0x14],0x2\n    1138:   7e 09                   jle    1143 &lt;main+0x1a&gt;\n    113a:   c7 45 fc 00 00 00 00    mov    DWORD PTR [rbp-0x4],0x0\n    1141:   eb 07                   jmp    114a &lt;main+0x21&gt;\n    1143:   c7 45 fc 01 00 00 00    mov    DWORD PTR [rbp-0x4],0x1\n    114a:   8b 45 fc                mov    eax,DWORD PTR [rbp-0x4]\n    114d:   5d                      pop    rbp\n    114e:   c3                      ret \n</code></pre></p> <p>It can be lifted to an IL like VEX, the IL used in the angr decompiler: <pre><code>00 | ------ IMark(0x401129, 4, 0) ------\n01 | PUT(rip) = 0x000000000040112d\n02 | ------ IMark(0x40112d, 1, 0) ------\n03 | t0 = GET:I64(rbp)\n04 | t8 = GET:I64(rsp)\n05 | t7 = Sub64(t8,0x0000000000000008)\n06 | PUT(rsp) = t7\n07 | STle(t7) = t0\n08 | ------ IMark(0x40112e, 3, 0) ------\n09 | PUT(rbp) = t7\n10 | PUT(rip) = 0x0000000000401131\n11 | ------ IMark(0x401131, 3, 0) ------\n12 | t10 = Add64(t7,0xffffffffffffffec)\n13 | t13 = GET:I64(rdi)\n14 | t25 = 64to32(t13)\n15 | t12 = t25\n16 | STle(t10) = t12\n17 | PUT(rip) = 0x0000000000401134\n18 | ------ IMark(0x401134, 4, 0) ------\n19 | t14 = Add64(t7,0xffffffffffffffec)\n20 | t5 = LDle:I32(t14)\n21 | PUT(cc_op) = 0x0000000000000007\n22 | t26 = 32Uto64(t5)\n23 | t16 = t26\n24 | PUT(cc_dep1) = t16\n25 | PUT(cc_dep2) = 0x0000000000000002\n26 | PUT(rip) = 0x0000000000401138\n27 | ------ IMark(0x401138, 2, 0) ------\n28 | t29 = 64to32(t16)\n29 | t30 = 64to32(0x0000000000000002)\n30 | t28 = CmpLE32S(t29,t30)\n31 | t27 = 1Uto64(t28)\n32 | t23 = t27\n33 | t31 = 64to1(t23)\n34 | t18 = t31\n35 | if (t18) { PUT(rip) = 0x401143; Ijk_Boring }\nNEXT: PUT(rip) = 0x000000000040113a; Ijk_Boring\n...\n</code></pre></p> <p>In the case of VEX, each <code>t</code> variable is only ever assigned once, making this SSA form.  You will also notice how verbose every instruction has become.  Even simple <code>mov</code> instructions, which assign a value to a register, have much more information now.  The lifted VEX above has been cut for brevity. </p> <ol> <li> <p>Song, Dawn, et al. \"BitBlaze: A new approach to computer security via binary analysis.\" Information Systems Security: 4<sup>th</sup> International Conference, ICISS 2008, Hyderabad, India, December 16-20, 2008. Proceedings 4. Springer Berlin Heidelberg, 2008.\u00a0\u21a9\u21a9</p> </li> <li> <p>Kinder, Johannes, and Helmut Veith. \"Jakstab: a static analysis platform for binaries: tool paper.\" Computer Aided Verification: 20<sup>th</sup> International Conference, CAV 2008 Princeton, NJ, USA, July 7-14, 2008 Proceedings 20. Springer Berlin Heidelberg, 2008.\u00a0\u21a9</p> </li> <li> <p>Brumley, David, et al. \"BAP: A binary analysis platform.\" Computer Aided Verification: 23<sup>rd</sup> International Conference, CAV 2011, Snowbird, UT, USA, July 14-20, 2011. Proceedings 23. Springer Berlin Heidelberg, 2011.\u00a0\u21a9</p> </li> <li> <p>Wang, Fish, and Yan Shoshitaishvili. \"Angr-the next generation of binary analysis.\" 2017 IEEE Cybersecurity Development (SecDev). IEEE, 2017.\u00a0\u21a9</p> </li> <li> <p>Gussoni, Andrea, et al. \"A comb for decompiled c code.\" Proceedings of the 15<sup>th</sup> ACM Asia Conference on Computer and Communications Security. 2020.\u00a0\u21a9</p> </li> <li> <p>Revng. \u201cRevng/Revng: Revng: The Core Repository of the Rev.Ng Project.\u201d GitHub, github.com/revng/revng. Accessed 27 Apr. 2024.\u00a0\u21a9</p> </li> <li> <p>Van Emmerik, Michael James. Static single assignment for decompilation. University of Queensland, 2007.\u00a0\u21a9</p> </li> <li> <p>Engel, Daniel, Freek Verbeek, and Binoy Ravindran. \"BIRD: A Binary Intermediate Representation for Formally Verified Decompilation of X86-64 Binaries.\" International Conference on Tests and Proofs. Cham: Springer Nature Switzerland, 2023.\u00a0\u21a9</p> </li> </ol>"},{"location":"fundamentals/cfg_recovery/overview/","title":"Overview","text":""},{"location":"fundamentals/cfg_recovery/overview/#introduction","title":"Introduction","text":"<p>A control flow graph (CFG) is a graph that describes the \"flow\" of execution in a program<sup>1</sup>.  As such, CFG recovery, in binary analysis, is the recovery of such a graph from binary code.  Since decompilation directly relies on this CFG, the recovery of it is considered fundamental to decompilation. </p> <p>This recovery can be broken up into multiple phases, some being optional depending on the decompilation target:</p> <ol> <li>Disassembling: the conversion of binary code to its mnemonic instructions and operands </li> <li>Program Lifting: the conversion disassembly to an intermediate language (IL) for better abstraction </li> <li>Function Recognition: the discovery of boundaries defining a function</li> <li>Indirect Jump Resolving: the resolution of jumps that have no constant target(s). </li> </ol> <p>The second phase, program lifting, is only required if the decompiler aims to be architecture agnostic. Most decompilers will use an IL to make their later analyses more widely applicable. </p> <p>Methods for evaluating improvements in this field are also of note but have had very limited work. The most recent of these works has focused on instrumenting and comparing to the compile-generated CFG<sup>2</sup><sup>3</sup>. </p> <p>There has been little work in replacing CFG recovery algorithms with a machine-learning model<sup>4</sup>. Related work in binary analysis has looked at how these recovered CFGs may be instrumentable<sup>5</sup>.</p>"},{"location":"fundamentals/cfg_recovery/overview/#graph-recovery-example","title":"Graph Recovery Example","text":"<p>An example C program is shown below: <pre><code>int main(int argc) {\n    int ret_code;\n    if(argc &gt; 2) {\n        ret_code = 0;\n    }\n    else {\n        ret_code = 1;\n    }\n    return ret_code;\n}\n</code></pre></p> <p>It is compiled on a x86-64 Linux machine with GCC, without optimizations: <pre><code>gcc example.c -o example &amp;&amp; objdump -D -M intel example | grep \"&lt;main&gt;:\" -A 12\n</code></pre></p> <p>After disassembling with objdump, which includes some function identification, we get the following disassembly: <pre><code>0000000000001129 &lt;main&gt;:\n    1129:   f3 0f 1e fa             endbr64\n    112d:   55                      push   rbp\n    112e:   48 89 e5                mov    rbp,rsp\n    1131:   89 7d ec                mov    DWORD PTR [rbp-0x14],edi\n    1134:   83 7d ec 02             cmp    DWORD PTR [rbp-0x14],0x2\n    1138:   7e 09                   jle    1143 &lt;main+0x1a&gt;\n    113a:   c7 45 fc 00 00 00 00    mov    DWORD PTR [rbp-0x4],0x0\n    1141:   eb 07                   jmp    114a &lt;main+0x21&gt;\n    1143:   c7 45 fc 01 00 00 00    mov    DWORD PTR [rbp-0x4],0x1\n    114a:   8b 45 fc                mov    eax,DWORD PTR [rbp-0x4]\n    114d:   5d                      pop    rbp\n    114e:   c3                      ret\n</code></pre></p> <p>In this example, the instructions at <code>0x1138</code> and <code>0x114a</code> cause the control flow to branch, resulting in the recovered graph:</p> <p></p> <p>Notice the implied edges coming from the assembly that looked linear (<code>0x114a</code>). The structure of the graph will also look the same if lifted to an IL.</p> <ol> <li> <p>Allen, Frances E. \"Control flow analysis.\" ACM Sigplan Notices 5.7 (1970): 1-19.\u00a0\u21a9</p> </li> <li> <p>Pang, Chengbin, et al. \"Ground truth for binary disassembly is not easy.\" 31<sup>st</sup> USENIX Security Symposium (USENIX Security 22). 2022.\u00a0\u21a9</p> </li> <li> <p>Pang, Chengbin, et al. \"Sok: All you ever wanted to know about x86/x64 binary disassembly but were afraid to ask.\" 2021 IEEE symposium on security and privacy (SP). IEEE, 2021.\u00a0\u21a9</p> </li> <li> <p>Yu, Shih-Yuan, et al. \"Cfg2vec: Hierarchical graph neural network for cross-architectural software reverse engineering.\" 2023 IEEE/ACM 45<sup>th</sup> International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP). IEEE, 2023.\u00a0\u21a9</p> </li> <li> <p>Di Bartolomeo, Luca, Hossein Moghaddas, and Mathias Payer. \"{ARMore}: Pushing Love Back Into Binaries.\" 32<sup>nd</sup> USENIX Security Symposium (USENIX Security 23). 2023.\u00a0\u21a9</p> </li> </ol>"},{"location":"misc/blogs/","title":"Community Blogs","text":"<p>A collection of decompilation blogs from the community.</p>"},{"location":"misc/blogs/#legend","title":"Legend","text":"<ul> <li>\ud83d\udc80: inactive (2 years without activity)</li> <li>\ud83d\udcbe: created by the developer or maintainer of a standalone decompiler</li> <li>\ud83d\udd0d: has posts on fundamental topics</li> <li>\u2699\ufe0f: has posts on applied research topics</li> <li>\ud83c\udf0d: utilizes decompilation for some means </li> </ul>"},{"location":"misc/blogs/#alphabetical-order","title":"Alphabetical Order","text":"<ul> <li>angr blog (\ud83d\udc80, \ud83d\udcbe, \ud83d\udd0d)</li> <li>Intranautic (\ud83d\udd0d)</li> <li>mahaloz (\ud83d\udcbe, \ud83d\udd0d, \ud83c\udf0d)</li> <li>fcd (\ud83d\udc80, \ud83d\udcbe, \ud83d\udd0d)</li> </ul>"}]}